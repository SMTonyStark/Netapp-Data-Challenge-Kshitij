{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import math\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\",dtype=object,na_values=str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[:,2:4])\n",
    "y = np.array(data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = []\n",
    "for i in range(0,x.shape[0]):\n",
    "    for sent in x[i]:\n",
    "        if np.nan_to_num(sent) == 0:     # If short description is missing\n",
    "            corpus_raw.append(\"NA\")      # Necessary, otherwise while feeding training data into NN can cause mismatch\n",
    "        elif np.nan_to_num(sent) != 0:\n",
    "            corpus_raw.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV', 'She left her husband. He killed their children. Just another day in America.', \"Will Smith Joins Diplo And Nicky Jam For The 2018 World Cup's Official Song\", 'Of course it has a song.', 'Hugh Grant Marries For The First Time At Age 57']\n",
      "(401664,)\n",
      "<class 'str'>\n",
      "NA\n"
     ]
    }
   ],
   "source": [
    "print(corpus_raw[0:5])\n",
    "print(np.shape(corpus_raw))\n",
    "print(type(corpus_raw[24199]))\n",
    "#words = corpus_raw[0].split()\n",
    "#print(words)\n",
    "print(np.nan_to_num(corpus_raw[24199]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of words\n",
    "words2 = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "i = 0\n",
    "for sent in corpus_raw:\n",
    "    #words.append(sent.split())\n",
    "    #i = i + 1\n",
    "    #print(i)\n",
    "    for word in tokenizer.tokenize(sent):\n",
    "        words2.append(word)\n",
    "    \n",
    "# for i in range(0,len(corpus_raw)):\n",
    "#     for word in corpus_raw[i].split():\n",
    "#         if word != '.':       # because we don't want to treat . as a word\n",
    "#             words.append(word)\n",
    "#print(type(words))\n",
    "#words = np.array(words)\n",
    "#print(type(words))\n",
    "#print(len(words))\n",
    "#print(words[0])\n",
    "\n",
    "Vocab = set(words2)    # so that all duplicate words are removed\n",
    "vocab = list(Vocab)\n",
    "# vocab = []\n",
    "# for j in words:\n",
    "#     if j not in vocab:\n",
    "#         vocab.append(j)\n",
    "\n",
    "\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(vocab)  # gives the total number of unique words\n",
    "\n",
    "for i,word in enumerate(vocab):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lists of words\n",
    "words = []\n",
    "sentences = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "i = 0\n",
    "for sent in corpus_raw:\n",
    "    #words.append(sent.split())\n",
    "    #i = i + 1\n",
    "    #print(i)\n",
    "    for word in tokenizer.tokenize(sent):\n",
    "        words.append(word)\n",
    "    sentences.append(words)\n",
    "    words = []\n",
    "# for i in range(0,len(corpus_raw)):\n",
    "#     for word in corpus_raw[i].split():\n",
    "#         if word != '.':       # because we don't want to treat . as a word\n",
    "#             words.append(word)\n",
    "#print(type(words))\n",
    "#words = np.array(words)\n",
    "#print(type(words))\n",
    "#print(len(words))\n",
    "#print(words[0])\n",
    "\n",
    "#Vocab = set(words)    # so that all duplicate words are removed\n",
    "#vocab = list(Vocab)\n",
    "# vocab = []\n",
    "# for j in words:\n",
    "#     if j not in vocab:\n",
    "#         vocab.append(j)\n",
    "\n",
    "\n",
    "# word2int = {}\n",
    "# int2word = {}\n",
    "# vocab_size = len(vocab)  # gives the total number of unique words\n",
    "\n",
    "# for i,word in enumerate(vocab):\n",
    "#     word2int[word] = i\n",
    "#     int2word[i] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "119541\n",
      "[]\n",
      "<class 'list'>\n",
      "119541\n",
      "119541\n",
      "401664\n",
      "[['There', 'Were', '2', 'Mass', 'Shootings', 'In', 'Texas', 'Last', 'Week', 'But', 'Only', '1', 'On', 'TV'], ['She', 'left', 'her', 'husband', 'He', 'killed', 'their', 'children', 'Just', 'another', 'day', 'in', 'America'], ['Will', 'Smith', 'Joins', 'Diplo', 'And', 'Nicky', 'Jam', 'For', 'The', '2018', 'World', 'Cup', 's', 'Official', 'Song'], ['Of', 'course', 'it', 'has', 'a', 'song'], ['Hugh', 'Grant', 'Marries', 'For', 'The', 'First', 'Time', 'At', 'Age', '57']]\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(vocab_size)\n",
    "print(words[0:100])\n",
    "print(type(vocab))\n",
    "#Vocab = list(vocab)\n",
    "#print(vocab[0:100])\n",
    "# for i in range(0,5):\n",
    "#     print(i)\n",
    "# for sent in corpus_raw:\n",
    "#     print(type(sent))\n",
    "print(len(word2int))\n",
    "print(len(int2word))\n",
    "#print(int2word)\n",
    "print(len(sentences))\n",
    "print(sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.array(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52701159, 60996040)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec = Word2Vec(sentences, size=100, window=5, min_count=0,workers=10,sg=0)\n",
    "model_word2vec.train(sentences,total_examples=len(sentences),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=119541, size=100, alpha=0.025)\n",
      "[-0.54685813  0.25076315  0.92616844  1.144328    2.0551136   1.5384881\n",
      " -0.62366205  1.0247073  -1.6796687  -0.8035525   0.8259742  -1.0985408\n",
      " -0.1364447   0.12807433  1.6307139   0.5654104  -0.12359933 -0.8720993\n",
      "  0.37266365 -1.0864244  -2.247471    0.7853427  -0.15346748  0.55016136\n",
      "  2.4135401  -0.4848523   1.8287183   0.8424177  -0.32662195 -1.6947381\n",
      "  0.6835333  -0.3748434  -0.7774773  -0.4060959  -0.7597703  -0.65643007\n",
      " -0.9999848  -0.52989835 -2.3733194  -1.5348572  -1.0939271   0.33598673\n",
      " -0.5725102  -0.06677867 -0.25671172 -0.70027655  1.2763828  -1.5107672\n",
      " -1.3437667   0.7893474  -0.5292094   0.5529111  -0.10230776 -1.3250577\n",
      " -0.98092145 -1.3715086   2.222861    0.503197   -2.4020553   2.5975807\n",
      " -0.7265535   0.8000334  -0.41110936 -1.1927834   1.0251832  -1.2498313\n",
      "  0.45622286  1.3940312  -0.9723995   0.6520696  -0.5341604   1.9899546\n",
      "  0.3732447   0.65729994  1.6611592   1.051633   -1.6209116   1.2629538\n",
      "  0.721418   -0.583883   -1.2154499  -1.1593882   2.3978102  -0.24477793\n",
      " -0.51187265 -1.1190127   1.1268268  -0.71238714 -0.4085758   2.0055277\n",
      "  0.3053603   1.681844    0.9328302   0.49435547 -1.0975772  -0.27729645\n",
      " -0.5347218  -1.1659162  -0.14804745 -0.6483677 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shooting', 0.7239995002746582), ('massacre', 0.7116231918334961), ('killings', 0.7032343149185181), ('deaths', 0.7009249925613403), ('incidents', 0.6998181343078613), ('mass', 0.6883281469345093), ('homicides', 0.6437969207763672), ('bombings', 0.6389467716217041), ('starvations', 0.6373001337051392), ('Newtown', 0.6355317831039429)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(model_word2vec)\n",
    "print(model_word2vec['killing'])\n",
    "print(model_word2vec.wv.most_similar(\"shootings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec.save(\"Saved_model_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=119541, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load(\"Saved_model_word2vec\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "embeddings = model[model.wv.vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(119541, 100)\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.7664075e-02  8.4760055e-02 -1.9771054e-02  6.4719141e-02\n",
      " -9.3166366e-02  1.5671920e-02  7.3042087e-02  1.5022810e-02\n",
      "  5.3337853e-02  2.8924717e-02  3.1462985e-03 -2.5344064e-02\n",
      "  5.0998092e-02 -1.3891241e-02 -8.0226980e-02 -4.7575094e-02\n",
      "  3.5614710e-02  1.5196036e-02  3.1290777e-02 -2.4902407e-02\n",
      " -1.6969467e-02  5.8391348e-02  6.8663195e-02  1.6878327e-02\n",
      "  4.8826538e-02 -7.7927448e-02 -1.3926639e-02  3.0664122e-02\n",
      " -6.0330216e-02  5.4414451e-02  1.9097341e-02  7.1145572e-02\n",
      " -3.5071369e-02 -2.4239130e-03  6.3200388e-03  8.5623979e-05\n",
      "  3.0584808e-02  1.2126015e-02 -8.8007599e-02 -7.5291684e-03\n",
      "  4.8049867e-02  3.7963040e-02 -1.3679477e-03  6.0370076e-03\n",
      " -7.0844352e-02  6.0902789e-02  1.2678598e-01 -2.5547266e-03\n",
      " -1.9077834e-02 -1.3249801e-02  5.1044647e-02 -6.7376364e-03\n",
      " -4.4337921e-02 -4.0173996e-02  5.1313840e-02 -1.3115887e-02\n",
      " -5.5694602e-02  1.5100859e-02  8.5642196e-02  1.2859231e-02\n",
      "  1.5273429e-02  1.7617268e-02 -1.5281208e-02  4.9232733e-02\n",
      "  2.1503551e-03  5.0989080e-02 -1.4187044e-01  6.7394659e-02\n",
      " -6.2957867e-03 -9.3536519e-02  3.5419747e-02 -7.9413794e-02\n",
      " -2.8534895e-02 -4.0326692e-02  5.0376769e-02 -1.1563549e-01\n",
      " -5.2494500e-03  5.3810287e-02 -1.1310673e-01 -2.7674457e-02\n",
      "  9.7582638e-02 -1.3206601e-02 -5.5982806e-02  1.3662921e-02\n",
      "  9.2756905e-02  1.2932754e-01 -2.2768548e-02 -4.3936849e-02\n",
      "  3.5449501e-02 -3.8287626e-04  9.6635111e-03 -5.4342591e-04\n",
      " -1.2015509e-02  2.7524564e-02  6.2323797e-02 -2.9328579e-02\n",
      "  9.1168083e-02  1.2254186e-02 -4.1930713e-02  1.7248457e-02]\n",
      "[ 3.1782370e+00 -4.1667771e-01  5.2466375e-01  1.7831213e+00\n",
      " -6.4418137e-01 -1.1207120e+00  1.5959555e-01 -8.7843513e-01\n",
      "  2.7283232e+00 -5.2879477e-01  2.4568248e+00  4.8660240e-01\n",
      "  8.2299298e-01 -2.0984986e+00 -2.8607314e+00  1.0811172e+00\n",
      " -2.6416392e+00  2.5562043e+00 -6.7723924e-01  3.8649440e-01\n",
      "  1.4338986e+00 -7.6113570e-01 -1.7335016e+00 -2.4737267e+00\n",
      "  4.9306636e+00 -1.0708356e+00 -3.4879191e+00 -3.4004035e+00\n",
      " -3.4656715e+00 -2.5280421e+00  2.7527654e+00  1.2111751e+00\n",
      " -1.9149337e+00  1.1123540e-01  1.6404920e+00  7.0291632e-01\n",
      "  8.4659296e-01  8.8962279e-02 -5.9246416e+00  4.0362421e-03\n",
      " -1.6310236e+00 -2.2530184e+00  1.5498326e+00 -4.2505021e+00\n",
      " -1.0081557e+00  6.8977141e-01  2.0436091e+00 -1.5410072e+00\n",
      "  3.4765215e+00 -2.5870543e+00  1.2777214e+00 -2.4491494e+00\n",
      " -2.3474772e+00  1.1489217e+00 -1.7145648e+00 -2.6419570e+00\n",
      "  2.0316253e+00  5.5447672e-03 -2.4276905e+00  3.3533125e+00\n",
      " -2.0849195e+00 -1.2146945e+00 -1.3240473e+00 -6.5444630e-01\n",
      "  6.8838969e-02 -4.4699163e+00 -1.6163398e+00 -2.6258595e+00\n",
      "  3.0892324e+00  7.5789088e-01  2.6458797e-01  1.0503672e+00\n",
      "  2.6944988e+00  4.3180776e+00  1.0802901e+00  3.9829719e-01\n",
      "  9.5877707e-01 -1.3185735e+00 -5.3045058e-01 -1.8807815e+00\n",
      " -4.2256489e+00  1.4206372e+00  1.1529354e+00 -2.2102857e+00\n",
      "  9.9182361e-01  2.0013934e-01  1.7684321e+00  1.9373126e-01\n",
      " -2.3833377e+00  2.6412103e+00  1.6038268e+00 -2.1112564e+00\n",
      "  8.0261832e-01  2.1006198e+00  3.5426218e-02 -8.9395511e-01\n",
      " -2.6115352e-01  6.3954985e-01  1.5780559e-01  6.0632610e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(embeddings[2])\n",
    "print(model['There'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependability\n",
      "Practicalities\n",
      "Rwandans\n",
      "Penthouse\n",
      "BARCELONA\n",
      "Lenkiewicz\n",
      "all\n",
      "Lynchpin\n",
      "Dearly\n",
      "Pregnancies\n"
     ]
    }
   ],
   "source": [
    "#print(word2int[0])\n",
    "for i in range(0,10):\n",
    "    print(int2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She', 'left', 'her', 'husband', 'He', 'killed', 'their', 'children', 'Just', 'another', 'day', 'in', 'America']\n"
     ]
    }
   ],
   "source": [
    "#word_vectors = np.zeros([],dtype=float)\n",
    "#print(words2[0:100])\n",
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5692329e+00 -3.0277991e+00 -1.0090363e+00  1.9246717e-01\n",
      " -3.8778777e+00 -1.9707137e-01  1.1885260e+00  1.8980798e+00\n",
      "  3.5624394e+00 -2.7961059e+00 -1.6923198e+00 -7.3978609e-01\n",
      "  3.4912262e+00  4.7844788e-01 -1.8613143e+00  2.6814097e-01\n",
      " -7.5292313e-01  8.9893353e-01  1.7882988e+00  3.5806286e+00\n",
      " -1.4572331e+00 -2.0116150e+00  9.3713030e-02 -2.3155227e+00\n",
      " -3.4935241e+00 -1.9114302e+00 -1.9495300e+00  5.1322207e+00\n",
      "  1.1074586e+00 -1.8300804e-03 -4.5545396e-01  7.3448730e-01\n",
      "  9.2049706e-01 -1.4450687e-01 -6.6794977e-02 -1.1179513e+00\n",
      "  2.3192902e-01 -1.1375239e+00 -4.4972296e+00 -2.1239340e+00\n",
      "  3.0149109e+00  9.4599456e-01  2.5476663e+00 -4.4285914e-01\n",
      "  3.3666785e+00  3.4619229e+00 -2.4715867e+00  1.9553204e-01\n",
      " -1.4509677e+00 -3.5955310e-01 -2.6171827e+00 -9.1040027e-01\n",
      "  1.8099520e-01  2.0810310e-03 -2.6360388e+00  3.5628765e+00\n",
      " -9.8851967e-01  2.4547322e+00 -8.1632996e-01  3.0644231e+00\n",
      " -1.5402031e+00  1.0574621e+00  3.1202373e-01 -2.4187140e+00\n",
      "  2.3699937e+00  3.6410048e+00 -2.1470058e+00 -9.7678238e-01\n",
      " -5.2546537e-01  4.2010489e-01 -1.6321693e-01 -1.0219197e+00\n",
      " -2.0449519e+00  5.6095779e-01 -1.4512217e+00  2.2306901e-01\n",
      " -5.5598974e-01 -1.4795978e-01 -6.7352521e-01 -8.3080754e-02\n",
      "  1.3763127e+00  1.7368119e+00 -2.9394944e+00  2.0805646e-01\n",
      " -7.5866318e-01 -1.6039091e+00 -2.3968832e+00  1.5464498e+00\n",
      "  1.8126670e+00 -3.7536418e+00  1.2435980e+00 -8.3051704e-02\n",
      " -4.0783840e-01  3.3646905e+00 -4.8306134e-01 -1.4877026e+00\n",
      "  2.0128167e+00  1.1643461e+00 -6.3926458e-01  7.4804127e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model[sentences[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
